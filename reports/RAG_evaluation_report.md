## Evaluating RAG-based vs. Non-RAG LLM Information Accuracy: A Case Study on Agni Tea Recipe

This report aims to compare the performance of RAG-based and non-RAG-based Large Language Models (LLMs) in terms of factual accuracy and information quality, with a specific focus on extremely domain-specific topics like Ayurveda. We conducted a case study using the "How to make agni tea?" query and the "The Complete Book of Ayurvedic Home Remedies" by Vasant Lad as the ground truth source.

### Methodology

1. **Query and Answers:** The query "How to make agni tea?" was presented to both models. Answers generated by the RAG-based and non-RAG-based models were recorded.
2. **True Answer:** The correct recipe was retrieved from the book, serving as the reference point for accuracy comparison.
3. **Word Embeddings:** SentenceTransformer was used to generate word embeddings for each answer and the true answer.
4. **Cosine Similarity:** Cosine similarity, a measure of textual similarity, was calculated between the true answer embedding and each model's answer embedding.

### Results

**True answer from the book:**
1 quart water
1⁄8 pinch cayenne pepper
1⁄2 handful minced ginger root
2 tablespoons Sucanat or other sweetener 1⁄8 to 1⁄2 teaspoon rock salt
Put all the above ingredients in a pot and boil for 20 minutes.
Take the pot o􏰂 the burner, cool for a few minutes, then add the juice of half a lime. Do not boil the lime juice.



**Answer provided by RAG-Based LLM:**
  Great! Here's a step-by-step guide on how to make Agni Tea:
Ingredients:
* 1 quart water
* Pinch of cayenne pepper
* Handful of minced ginger root
* 2 tablespoons Sucanat or other sweetener (optional)
* Rock salt (optional)

Instructions:

1. Start by bringing the water to a boil in a pot.
2. Once the water is boiling, add the pinch of cayenne pepper and stir well.
3. Next, add the handful of minced ginger root to the pot and stir again.
4. Add the 2 tablespoons of Sucanat or other sweetener (if using) and stir well.
5. If desired, add a small amount of rock salt to the pot and stir to combine.
6. Reduce the heat to a simmer and let the tea steep for 20 minutes.
7. Strain the tea into a cup and enjoy!
Note: You can adjust the amount of cayenne pepper to your liking, depending on how much heat you prefer in your tea. Some people find that a small amount of cayenne pepper has a stimulating effect on digestion, while others may prefer more or less. Experiment and find the amount that works best for you.
Agni Tea is a traditional Ayurvedic recipe that is designed to stimulate the digestive fire and promote healthy digestion. The ginger root in the tea helps to warm and stimulate the digestive system, while the cayenne pepper adds a subtle kick of heat that can help to break down food and promote digestion. The sweetener (if used) can help to balance the flavor of the tea and make it more enjoyable to drink.
I hope you enjoy making and drinking Agni Tea! Let me know if you have any questions or need further clarification on the recipe.



**Answer provided by non-RAG LLM:**
Agni tea is a traditional Ayurvedic tea that is made by infusing herbs and spices in hot water. Here is a simple recipe for making agni tea at home:
Ingredients:

* 2 teaspoons of ginger powder
* 2 teaspoons of cinnamon powder
* 2 teaspoons of black pepper
* 1 teaspoon of turmeric powder
* 1 teaspoon of ginger oil
* 1 teaspoon of cinnamon oil
* 1 teaspoon of black pepper oil
* 1 teaspoon of honey (optional)

Instructions:

1. Boil water in a pot and let it cool to a comfortable temperature for drinking.
2. In a small bowl, mix together the ginger powder, cinnamon powder, black pepper, and turmeric powder.
3. Add the herbal mixture to the boiling water and stir well.
4. Reduce the heat to low and let the tea steep for 5-10 minutes, or until the desired flavor is achieved.
5. Strain the tea into a cup and discard the solids.
6. Add the ginger oil, cinnamon oil, and black pepper oil to the tea and stir well.
7. If desired, add honey to sweeten the tea.
8. Serve the agni tea hot, or let it cool to room temperature and drink it as a refreshing beverage.
Tips:

* You can adjust the amount of each ingredient to suit your taste preferences.
* Adding a slice of ginger or a cinnamon stick to the tea can enhance the flavor and aroma.
* You can also add other herbs and spices to the tea, such as cloves, cardamom, or fennel seeds, to create a unique flavor profile.
* Agni tea can be consumed as a daily tonic to promote digestion and overall well-being, or as a pre-bedtime tea to aid in relaxation and sleep.
* Store any leftover agni tea in an airtight container in the refrigerator for up to 3 days.
I hope this helps you make a delicious and healthy agni tea at home!


### Scores

| Model | Cosine Similarity Score |
|---|---|
| True | - (Reference) |
| RAG-based LLM | 0.6471 |
| Non-RAG LLM | 0.5113 |

### Analysis

- The RAG-based LLM achieved a higher cosine similarity score (0.6471) compared to the non-RAG LLM (0.5113) when both answers were compared to the true answer from the book. This indicates that the RAG-based LLM's answer was textually closer to the accurate recipe. It looks like the non-RAG LLM gave a generic masala chai recipe instead of specifically the agni tea recipe.
- While the difference in scores might seem small, it signifies a stronger contextual alignment of the RAG-based LLM's answer with the factual details and specific ingredients mentioned in the reference source. This suggests that RAG-based models, by leveraging external knowledge bases, can potentially produce more factually accurate responses, especially in highly specialized domains like Ayurveda.

### Importance of RAGs for Domain-Specific Topics

Ayurveda is a complex and nuanced medical system with its own terminology, concepts, and ingredients. Traditional LLMs might struggle to grasp the intricacies of such domains, leading to factually incorrect or incomplete information. RAG-based LLMs, on the other hand, can access and integrate knowledge from external sources specifically tailored to the domain, resulting in more accurate and relevant responses. In domains like Ayurveda, where precision is crucial, RAG-based LLMs hold significant potential for improved information retrieval and knowledge dissemination.

### Limitations

- This study used the Llama2 7B model, limiting domain coverage as well as ability to generate more nuanced answers.
- Cosine similarity only measures textual similarity, not necessarily factual accuracy.
- The chosen book might not be representative of all sources within ayurveda.

### Conclusion

This case study provides preliminary evidence that RAG-based LLMs might have an advantage over non-RAG LLMs in terms of factual accuracy, especially when dealing with extremely domain-specific topics like Ayurveda. Further research with more diverse queries, models, and evaluation methods is needed to draw more definitive conclusions.

### Code (also in the rag_model jupyter notebook within the notebooks folder)

```python
def get_embedding(text):
    """
    Generate an embedding for a given text.

    Args:
    - text (str): The input text.
    
    Returns:
    - The sentence embedding.
    """
    # Load the sentence transformer model
    model = SentenceTransformer('all-MiniLM-L6-v2')
    # Generate the sentence embeddings
    embeddings = model.encode(text, convert_to_tensor=True)
    return embeddings


def calculate_cosine_similarity(embedding1, embedding2):
    """
    Calculate the cosine similarity between two embeddings.

    Args:
    - embedding1 (torch.Tensor): The first embedding.
    - embedding2 (torch.Tensor): The second embedding.

    Returns:
    - The cosine similarity score.
    """
    # Calculate the cosine similarity
    if len(embedding1.shape) == 1:
        embedding1 = embedding1.unsqueeze(0)
    if len(embedding2.shape) == 1:
        embedding2 = embedding2.unsqueeze(0)
    similarity = torch.nn.functional.cosine_similarity(embedding1, embedding2, dim=1)
    return similarity.item()


def calculate_similarity_scores(true_answer, rag_answer, non_rag_answer):
     """
    Calculate the cosine similarity scores between the true answer and both RAG-based and non-RAG-based answers.

    Args:
    - true_answer (str): The true answer text.
    - rag_answer (str): The RAG-based model's answer text.
    - non_rag_answer (str): The non-RAG-based model's answer text.

    Returns:
    - A dictionary with cosine similarity scores.
    """
    # Convert the answers to embeddings
    true_answer_embedding = get_embedding(true_answer)
    rag_answer_embedding = get_embedding(rag_answer)
    non_rag_answer_embedding = get_embedding(non_rag_answer)
    
    # Calculate cosine similarity scores
    rag_similarity = calculate_cosine_similarity(true_answer_embedding, rag_answer_embedding)
    non_rag_similarity = calculate_cosine_similarity(true_answer_embedding, non_rag_answer_embedding)

    
    # Return the scores
    return {
        "RAG Similarity Score": rag_similarity,
        "Non-RAG Similarity Score": non_rag_similarity
    }


# Calculate the similarity scores
similarity_scores = calculate_similarity_scores(true_answer, rag_answer, non_rag_answer)
print(similarity_scores)