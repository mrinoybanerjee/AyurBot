{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AyurBot: Using RAG Based LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "MONGODB_CONNECTION_STRING = os.getenv(\"MONGODB_URI\")\n",
    "MONGODB_DATABASE = os.getenv(\"MONGODB_DATABASE\")\n",
    "MONGODB_COLLECTION = os.getenv(\"MONGODB_COLLECTION\")\n",
    "API_TOKEN = os.getenv(\"API_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text extraction from Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the data from the file\n",
    "import re\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_document = fitz.open('/Users/mrinoyb2/git/AyurBot/Data/pdf/Ayurveda_Book.pdf')\n",
    "\n",
    "# Function to preprocess and clean text\n",
    "def preprocess_text_mupdf(text):\n",
    "    # Remove headers/footers\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # Remove empty lines\n",
    "    text = re.sub(r'[^A-Za-z0-9.,;:!?()\\'\\\"\\n]+', ' ', text)  # Remove special characters but keep punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with single space\n",
    "    return text.strip()\n",
    "\n",
    "# Extract and clean text\n",
    "cleaned_text_mupdf = \"\"\n",
    "for page_number in range(pdf_document.page_count):\n",
    "    page = pdf_document.load_page(page_number)\n",
    "    text = page.get_text()\n",
    "    cleaned_text_mupdf += preprocess_text_mupdf(text)\n",
    "\n",
    "# Close the PDF document\n",
    "pdf_document.close()\n",
    "\n",
    "# Output the first \n",
    "print(cleaned_text_mupdf)\n",
    "\n",
    "# Save the cleaned text to a file\n",
    "with open('/Users/mrinoyb2/git/AyurBot/Data/clean_text/Ayurveda_Book.txt', 'w') as file:\n",
    "    file.write(cleaned_text_mupdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store chunks in MongoDB database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "# Connect to MongoDB (Update the connection string as per your MongoDB setup)\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Chunking the text by sentence to boost accurate retrieval\n",
    "def chunk_by_sentence(text):\n",
    "    sentences = []\n",
    "    tmp_sentence = \"\"\n",
    "    for char in text:\n",
    "        if char in [\".\", \"!\", \"?\"]:\n",
    "            sentences.append(tmp_sentence)\n",
    "            tmp_sentence = \"\"\n",
    "        else:\n",
    "            tmp_sentence += char\n",
    "    # Add any remaining text as the last sentence\n",
    "    if tmp_sentence:\n",
    "        sentences.append(tmp_sentence)\n",
    "    return sentences\n",
    "    \n",
    "\n",
    "# Chunk the text\n",
    "chunks = chunk_by_sentence(cleaned_text_mupdf)\n",
    "\n",
    "# Store chunks in MongoDB\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    # Create a document for each chunk\n",
    "    document = {\"_id\": idx, \"text\": chunk}\n",
    "    # Insert the document into the collection\n",
    "    collection.insert_one(document)\n",
    "\n",
    "print(f\"Total chunks stored in MongoDB: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pymongo\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "chunks_collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Load the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to update documents with embeddings\n",
    "def update_documents_with_embeddings():\n",
    "    for document in chunks_collection.find():\n",
    "        # Generate embedding\n",
    "        embedding = model.encode(document['text'], convert_to_tensor=False)\n",
    "        # Update document with embedding\n",
    "        chunks_collection.update_one({'_id': document['_id']}, {'$set': {'embedding': embedding.tolist()}})\n",
    "\n",
    "# Uncomment the following line to run the embedding update\n",
    "update_documents_with_embeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic search retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 (Score: 0.653): Whatever the cause of your backache, the following natural Ayurvedic home remedies will be helpful....\n",
      "Result 2 (Score: 0.645): Following these guidelines will help you heal your aching back as well as avoid backpain in the futu...\n",
      "Result 3 (Score: 0.563): Backache can also be relieved by the use of the herb musta, which is a muscle painkiller....\n",
      "Result 4 (Score: 0.529): Some gentle yoga exercises can help with back pain....\n",
      "Result 5 (Score: 0.519): For extra healing and muscle relaxation, apply the mahanarayan oil on your back and then follow with...\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pymongo\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "db = client[MONGODB_DATABASE]\n",
    "chunks_collection = db[MONGODB_COLLECTION]\n",
    "\n",
    "# Function to perform semantic search\n",
    "def semantic_search(query, top_k=5):\n",
    "    # Generate query embedding\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    query_embedding = model.encode(query, convert_to_tensor=False)\n",
    "    \n",
    "    # Retrieve all embeddings from MongoDB and calculate similarity\n",
    "    similarities = []\n",
    "    for document in chunks_collection.find():\n",
    "        doc_embedding = np.array(document['embedding'])\n",
    "        similarity = 1 - cosine(query_embedding, doc_embedding)  # Higher score means more similar\n",
    "        similarities.append((document['_id'], similarity, document['text']))\n",
    "    \n",
    "    # Sort by similarity score in descending order\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top_k most similar documents\n",
    "    return similarities[:top_k]\n",
    "\n",
    "# Example usage\n",
    "query = \"How to cure backpain?\"\n",
    "results = semantic_search(query)\n",
    "for idx, (doc_id, similarity, text) in enumerate(results, start=1):\n",
    "    print(f\"Result {idx} (Score: {similarity:.3f}): {text[:100]}...\")  # Print the first 100 characters for brevity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "from replicate.client import Client\n",
    "import os\n",
    "\n",
    "# Function to generate an answer using LLama2 from Replicate\n",
    "def generate_answer(question, max_context_length=1000):\n",
    "    # Assume semantic_search is defined and returns relevant context as a single string\n",
    "    context_results = semantic_search(question, top_k=1)\n",
    "    if context_results:\n",
    "        context = context_results[0][2]  # Get the text of the top result\n",
    "        # Truncate context if it exceeds the maximum length\n",
    "        if len(context) > max_context_length:\n",
    "            context = context[:max_context_length]\n",
    "        prompt = f\"[INST]\\nQuestion: {question}\\nContext: {context}\\n[/INST]\"\n",
    "        print(prompt)\n",
    "    else:\n",
    "        prompt = f\"[INST]\\nQuestion: {question}\\n[/INST]\"  # Fallback in case no context is found\n",
    "    \n",
    "   \n",
    "    client = Client(api_token=API_TOKEN)\n",
    "\n",
    "    # Generate the answer using LLama2 from Replicate\n",
    "    output = client.run(\n",
    "        \"nwhitehead/llama2-7b-chat-gptq:8c1f632f7a9df740bfbe8f6b35e491ddfe5c43a79b43f062f719ccbe03772b52\",\n",
    "        input={\n",
    "            \"seed\": -1,\n",
    "            \"top_k\": 20,\n",
    "            \"top_p\": 1,\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": 1024,\n",
    "            \"min_tokens\": 1,\n",
    "            \"temperature\": 0.5,\n",
    "            \"repetition_penalty\": 1\n",
    "        }\n",
    "    )\n",
    "    answer = \"\"\n",
    "    for item in output:\n",
    "        answer += item\n",
    "        \n",
    "    # Handle the case where the answer is empty\n",
    "    if not answer:\n",
    "        answer = \"Sorry, I don't have an answer for that.\"\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]\n",
      "Question: What is Ayurveda?\n",
      "Context: AYURVEDA.\n",
      "[/INST]\n",
      "  Ayurveda is a traditional system of medicine and healthy living that originated in India over 5,000 years ago. The term \"Ayurveda\" is derived from the Sanskrit words \"ayur\" meaning \"life\" and \"veda\" meaning \"science\" or \"knowledge.\" It is based on the belief that the mind, body, and spirit are interconnected and that imbalances in any one of these areas can lead to disease.\n",
      "Ayurveda emphasizes the use of natural remedies, such as herbs, yoga, and meditation, to promote overall wellness and balance in the body. It also focuses on prevention and early detection of disease, rather than just treating symptoms after they have already developed.\n",
      "The core principles of Ayurveda are:\n",
      "1. The body is made up of five elements (earth, water, fire, air, and ether) and three doshas (Vata, Pitta, and Kapha). Imbalances in these elements and doshas can lead to disease.\n",
      "2. The body has a natural healing mechanism, and Ayurveda seeks to enhance this process by using natural remedies and treatments.\n",
      "3. The mind and body are interconnected, and mental and emotional state can affect physical health, and vice versa.\n",
      "4. The environment and lifestyle play a significant role in maintaining good health, and Ayurveda provides guidelines for a healthy lifestyle, including diet, exercise, and stress management.\n",
      "5. Prevention is better than cure, and Ayurveda emphasizes the importance of maintaining good health through preventive measures, such as early detection of disease and taking steps to prevent it from developing in the first place.\n",
      "Ayurveda has been practiced for thousands of years in India and has been influential in shaping the country's medical systems. It is still widely practiced today and has gained popularity worldwide due to its holistic approach to health and wellness.\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"What is Ayurveda?\"\n",
    "answer = generate_answer(query)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
